# RaftEx

A complete, spec-faithful implementation of the Raft consensus algorithm in Elixir.

> "In Search of an Understandable Consensus Algorithm"  
> â€” Ongaro & Ousterhout (2014)

Every rule from the paper is implemented and cited. Every invariant has a test.

---

## What's implemented

| Paper Section | Feature |
|---|---|
| Â§5.1 | Persistent state â€” `currentTerm`, `votedFor`, `log[]` written to DETS before any RPC |
| Â§5.2 | Leader election â€” randomized timeout (150â€“300ms), RequestVote, majority vote counting |
| Â§5.3 | Log replication â€” AppendEntries with all 5 receiver rules, `nextIndex`/`matchIndex` |
| Â§5.4.1 | Election restriction â€” log up-to-date check (term first, then length) |
| Â§5.4.2 | Commit discipline â€” leader only advances `commitIndex` for current-term entries |
| Â§5.5 | Fault tolerance â€” follower crash, leader crash, automatic re-election and catch-up |
| Â§5.6 | Timing â€” 50ms heartbeat `<<` 150â€“300ms election timeout |
| Â§6 | Joint consensus â€” `C_old,new` two-phase membership change, graceful node removal |
| Â§7 | Log compaction â€” snapshot create/load, `InstallSnapshot` RPC, log truncation |
| Â§8 | Client interaction â€” redirect to leader, no-op on election, linearizable reads |

---

## Project structure

```
raft_ex_v2/
â”œâ”€â”€ lib/raft_ex/
â”‚   â”œâ”€â”€ server.ex        # :gen_statem FSM â€” follower/candidate/leader roles
â”‚   â”œâ”€â”€ log.ex           # DETS-backed log storage
â”‚   â”œâ”€â”€ persistence.ex   # DETS-backed currentTerm + votedFor
â”‚   â”œâ”€â”€ rpc.ex           # Message structs (AppendEntries, RequestVote, InstallSnapshot)
â”‚   â”œâ”€â”€ cluster.ex       # Peer list, majority/joint-majority helpers
â”‚   â”œâ”€â”€ state_machine.ex # KV store â€” set/get/delete
â”‚   â”œâ”€â”€ snapshot.ex      # Snapshot create/load/install
â”‚   â”œâ”€â”€ inspector.ex     # Telemetry handler â€” prints every event to stdout
â”‚   â””â”€â”€ application.ex   # OTP supervision tree
â”œâ”€â”€ lib/raft_ex.ex        # Public API
â”œâ”€â”€ scripts/demo.exs      # Full interactive demo
â””â”€â”€ test/raft_ex/
    â”œâ”€â”€ persistence_test.exs
    â”œâ”€â”€ log_test.exs
    â”œâ”€â”€ rpc_test.exs
    â”œâ”€â”€ cluster_test.exs
    â”œâ”€â”€ state_machine_test.exs
    â”œâ”€â”€ snapshot_test.exs
    â”œâ”€â”€ server_unit_test.exs
    â”œâ”€â”€ fault_tolerance_test.exs
    â””â”€â”€ joint_consensus_test.exs
```

---

## Quick start

```bash
cd raft_ex_v2
mix deps.get
mix compile
```

Run the full demo (shows every state transition, RPC, vote, commit, and apply):

```bash
mix run scripts/demo.exs
```

Run all tests:

```bash
mix test
```

---

## Using the API

### Start a cluster

```elixir
cluster = [:n1, :n2, :n3]

# Start each node â€” all nodes need to know the full cluster
{:ok, _} = RaftEx.start_node(:n1, cluster)
{:ok, _} = RaftEx.start_node(:n2, cluster)
{:ok, _} = RaftEx.start_node(:n3, cluster)

# Wait for election (150â€“300ms)
Process.sleep(500)
```

### Find the leader

```elixir
leader = RaftEx.find_leader(cluster)
# => :n1  (whichever won the election)
```

### Write and read data

```elixir
{:ok, "alice"} = RaftEx.set(leader, "username", "alice")
{:ok, "alice"} = RaftEx.get(leader, "username")
{:ok, :ok}     = RaftEx.delete(leader, "username")
```

### Send a command to any node (auto-redirects to leader)

```elixir
# Works even if you don't know who the leader is
{:ok, result} = RaftEx.command(cluster, {:set, "key", "value"})
```

### Inspect node state

```elixir
RaftEx.status(:n1)
# => %{
#   node_id: :n1,
#   role: :follower,
#   current_term: 3,
#   commit_index: 7,
#   last_applied: 7,
#   leader_id: :n2,
#   log_last_index: 7,
#   sm_state: %{"username" => "alice"}
# }
```

### Stop a node

```elixir
RaftEx.stop_node(:n1)
```

### Cluster membership change (Â§6)

```elixir
# Add a node â€” start it first, then submit config_change
{:ok, _} = RaftEx.start_node(:n4, [:n1, :n2, :n3, :n4])
{:ok, _} = RaftEx.Server.command(leader, {:config_change, [:n1, :n2, :n3, :n4]})

# Remove a node â€” submit config_change, node shuts down after commit
{:ok, _} = RaftEx.Server.command(leader, {:config_change, [:n1, :n2, :n3]})
```

### Create a snapshot (Â§7)

```elixir
s = RaftEx.status(leader)
{:ok, snap} = RaftEx.Snapshot.create(
  leader,
  s.commit_index,
  s.current_term,
  cluster,
  s.sm_state
)
# snap.last_included_index, snap.last_included_term, snap.data
```

---

## How it works

### Roles

Each node runs as a `:gen_statem` with three named state functions:

- **`follower/3`** â€” default state; resets election timer on valid heartbeat or vote grant
- **`candidate/3`** â€” increments term, votes for self, sends `RequestVote` to all peers
- **`leader/3`** â€” sends heartbeats every 50ms, replicates log entries, advances `commitIndex`

### Persistence

Before responding to any RPC, the server writes to DETS:

```
{:raft_meta, node_id}  â†’  {:current_term, N}  and  {:voted_for, atom | nil}
{:raft_log, node_id}   â†’  {index, term, command}  entries
```

On restart, these are loaded back before the FSM starts â€” `currentTerm` never goes backward.

### Log replication flow

```
Client â†’ leader.command/2
  â†’ Log.append (DETS)
  â†’ AppendEntries to all peers
  â†’ peers reply AppendEntriesReply{success: true, match_index: N}
  â†’ leader advances matchIndex[peer]
  â†’ maybe_advance_commit: if majority have matchIndex >= N and log[N].term == currentTerm
  â†’ apply_committed_entries: StateMachine.apply_entries
  â†’ reply to client
```

### Observability

Every event emits a `:telemetry` event and is printed by `RaftEx.Inspector`:

```
[NODE :n1] [LEADER] ğŸ“ appended index=4 term=2 cmd={:set, "key", "val"}
[NODE :n1] â†’ SEND AppendEntries to n2
[NODE :n2] â† REPLY AppendEntriesReply to n1
[NODE :n1] âœ” COMMITTED up to index=4
[NODE :n1] âš™ APPLIED index=4 result={:ok, "val"}
```

---

## Tests

```
4 properties, 124 tests, 0 failures
```

| File | What it tests |
|---|---|
| `persistence_test.exs` | DETS read/write, crash recovery |
| `log_test.exs` | Append, truncate, conflict detection, property tests |
| `rpc_test.exs` | Struct construction and serialization |
| `cluster_test.exs` | Majority, joint majority, peer list |
| `state_machine_test.exs` | KV set/get/delete, apply_entries |
| `snapshot_test.exs` | Create, load, install |
| `server_unit_test.exs` | FSM logic â€” election, replication, commit |
| `fault_tolerance_test.exs` | Leader crash, follower crash, network partition |
| `joint_consensus_test.exs` | Â§6 node removal shutdown, joint majority voting |

---

## Timing constants

| Constant | Value | Paper ref |
|---|---|---|
| Election timeout | 150â€“300ms (random) | Â§5.2 |
| Heartbeat interval | 50ms | Â§5.2 |
| RPC call timeout | 5000ms | Â§8 |

---

## Reference

- Paper: https://raft.github.io/raft.pdf  
- Visualization: https://raft.github.io  
- Elixir docs: https://elixir-lang.org/docs.html
